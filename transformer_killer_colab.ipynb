{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Lean Infinity Dual Hybrid v1 - Google Colab\n",
    "\n",
    "This notebook runs the unified **Lean Infinity Dual Hybrid v1** benchmarks on Google Colab with GPU support.\n",
    "\n",
    "**Controllers available (LM mode):**\n",
    "- `transformer` - Standard Transformer decoder (baseline)\n",
    "- `mamba` - Mamba backbone (Mamba2 CUDA if installed, GRU fallback)\n",
    "- `mamba_dualmem` - Mamba + DualTierMiras parametric memory\n",
    "\n",
    "**Benchmarks (LM mode):**\n",
    "- Synthetic sequence tasks: `copy_memory`, `assoc_recall`, `selective_copy`, `induction_head`\n",
    "\n",
    "**Entrypoint:**\n",
    "- `python -m trans_mamba_core.unified_runner --mode lm ...`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your zip file\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Upload Trans_MAMBA-lean-infinity-dual-hybrid-v1.zip:\")\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip\n",
    "!unzip -o Trans_MAMBA-lean-infinity-dual-hybrid-v1.zip -d /content\n",
    "%cd /content/Trans_MAMBA-lean-infinity-dual-hybrid-v1\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run unified setup script (installs PyTorch, dependencies, and optionally Mamba CUDA)\\n# This handles everything automatically!\\n!python setup_colab.py --install-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Install Mamba2 from LOCAL SOURCE (takes ~5 min to compile)\\n# This gives better performance than the PyPI version\\n# Uncomment to enable:\\n\\n# !python setup_colab.py --install-mamba-source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (Optional) Install Mamba2 CUDA Kernels\n",
    "\n",
    "This enables real Mamba2 SSM layers instead of GRU fallback. Skip if you want faster setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Install real Mamba2 from LOCAL SOURCE (takes ~5 min to compile)\n",
    "# Uncomment to enable:\n",
    "\n",
    "# %cd /content/Trans_MAMBA-lean-infinity-dual-hybrid-v1/external/mamba_ssm\n",
    "# !pip install -e . --quiet\n",
    "# %cd /content/Trans_MAMBA-lean-infinity-dual-hybrid-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sanity Check\n",
    "\n",
    "Verify all components work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m trans_mamba_core.unified_runner \\\n",
    "    --mode lm --task copy_memory --controller mamba_dualmem \\\n",
    "    --seq_len 64 --delay 16 --epochs 1 --batch_size 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Synthetic Benchmarks\n",
    "\n",
    "### 4.1 Copy Memory Task\n",
    "\n",
    "Tests ability to copy a sequence after a delay period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer baseline\n",
    "!python -m trans_mamba_core.unified_runner \\\n",
    "    --mode lm --task copy_memory \\\n",
    "    --controller transformer \\\n",
    "    --seq_len 100 --delay 40 \\\n",
    "    --epochs 20 --batch_size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mamba baseline\n",
    "!python -m trans_mamba_core.unified_runner \\\n",
    "    --mode lm --task copy_memory \\\n",
    "    --controller mamba \\\n",
    "    --seq_len 100 --delay 40 \\\n",
    "    --epochs 20 --batch_size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mamba + DualTierMiras\n",
    "!python -m trans_mamba_core.unified_runner \\\n",
    "    --mode lm --task copy_memory \\\n",
    "    --controller mamba_dualmem \\\n",
    "    --seq_len 100 --delay 40 \\\n",
    "    --epochs 20 --batch_size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The v1 unified runner does not expose an `ot_agent` controller in LM mode.\n",
    "# Use `mamba_dualmem` as the long-context baseline for these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Associative Recall Task\n",
    "\n",
    "Tests content-addressable memory retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all controllers on associative recall\n",
    "for controller in [\"transformer\", \"mamba\", \"mamba_dualmem\"]:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Controller: {controller}\")\n",
    "    print(\"=\" * 60)\n",
    "    !python -m trans_mamba_core.unified_runner \\\n",
    "        --mode lm --task assoc_recall \\\n",
    "        --controller {controller} \\\n",
    "        --seq_len 30 --num_pairs 6 \\\n",
    "        --epochs 20 --batch_size 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Notes on LM Benchmarks\n",
    "\n",
    "The v1 core focuses on **synthetic sequence tasks** via `trans_mamba_core.unified_runner --mode lm`.\n",
    "\n",
    "If you want to run a true text-corpus LM benchmark, we can extend the runner to accept `--data_path` again,\n",
    "or add a separate script that wraps `trans_mamba_core.synthetic.lm_bench` against a tokenized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Download a sample corpus (Shakespeare)\n",
    "# This is not consumed by the v1 unified runner yet, but kept here for convenience.\n",
    "!wget -q https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -O /content/corpus.txt\n",
    "!head -20 /content/corpus.txt\n",
    "!wc -c /content/corpus.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Induction Head synthetic task\n",
    "!python -m trans_mamba_core.unified_runner \\\n",
    "    --mode lm --task induction_head \\\n",
    "    --controller transformer \\\n",
    "    --seq_len 128 \\\n",
    "    --epochs 10 --batch_size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Selective Copy synthetic task\n",
    "!python -m trans_mamba_core.unified_runner \\\n",
    "    --mode lm --task selective_copy \\\n",
    "    --controller mamba_dualmem \\\n",
    "    --seq_len 128 --delay 40 \\\n",
    "    --epochs 10 --batch_size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: RL mode quick run (CartPole)\n",
    "!python -m trans_mamba_core.unified_runner \\\n",
    "    --mode rl --agent infinity --env cartpole \\\n",
    "    --num_updates 20 --log_interval 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Full Comparison (All Controllers)\n",
    "\n",
    "Run a comprehensive comparison and save logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Create logs directory\n",
    "log_dir = Path(\"/content/logs\")\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "controllers = [\"transformer\", \"mamba\", \"mamba_dualmem\"]\n",
    "tasks = [\"copy_memory\", \"assoc_recall\"]\n",
    "\n",
    "for task in tasks:\n",
    "    for controller in controllers:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Task: {task} | Controller: {controller}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        extra_args = [\"--delay\", \"40\"] if task == \"copy_memory\" else [\"--num_pairs\", \"6\"]\n",
    "        seq_len = \"100\" if task == \"copy_memory\" else \"30\"\n",
    "\n",
    "        !python -m trans_mamba_core.unified_runner \\\n",
    "            --mode lm --task {task} \\\n",
    "            --controller {controller} \\\n",
    "            --seq_len {seq_len} \\\n",
    "            --epochs 20 --batch_size 64 \\\n",
    "            --save_dir {str(log_dir)} \\\n",
    "            {\" \".join(extra_args)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View saved logs\n",
    "!ls -la /content/logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "log_dir = Path(\"/content/logs\")\n",
    "results = []\n",
    "\n",
    "for path in sorted(log_dir.glob(\"*.json\")):\n",
    "    with open(path) as f:\n",
    "        payload = json.load(f)\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"task\": payload.get(\"task\"),\n",
    "            \"controller\": payload.get(\"controller\"),\n",
    "            \"final_accuracy\": payload.get(\"results\", {}).get(\"final_accuracy\"),\n",
    "            \"best_accuracy\": payload.get(\"results\", {}).get(\"best_accuracy\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(f\"{'Task':<15} {'Controller':<15} {'Final Acc':<10} {'Best Acc':<10}\")\n",
    "print(\"-\" * 55)\n",
    "for r in results:\n",
    "    final_acc = r[\"final_accuracy\"]\n",
    "    best_acc = r[\"best_accuracy\"]\n",
    "    final_s = f\"{final_acc:.4f}\" if isinstance(final_acc, (int, float)) else \"N/A\"\n",
    "    best_s = f\"{best_acc:.4f}\" if isinstance(best_acc, (int, float)) else \"N/A\"\n",
    "    print(f\"{r['task']:<15} {r['controller']:<15} {final_s:<10} {best_s:<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip and download logs\n",
    "!zip -r /content/benchmark_logs.zip /content/logs\n",
    "\n",
    "from google.colab import files\n",
    "files.download('/content/benchmark_logs.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Custom Experiments\n",
    "\n",
    "Modify parameters below for your own experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom experiment parameters\n",
    "CONTROLLER = \"mamba_dualmem\"  # transformer, mamba, mamba_dualmem\n",
    "TASK = \"copy_memory\"          # copy_memory, assoc_recall, selective_copy, induction_head\n",
    "SEQ_LEN = 200                 # Sequence length\n",
    "DELAY = 80                    # Delay for copy_memory\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "extra_args = \"--delay {}\".format(DELAY) if TASK == \"copy_memory\" else \"\"\n",
    "\n",
    "!python -m trans_mamba_core.unified_runner \\\n",
    "    --mode lm --task {TASK} \\\n",
    "    --controller {CONTROLLER} \\\n",
    "    --seq_len {SEQ_LEN} {extra_args} \\\n",
    "    --epochs {EPOCHS} --batch_size {BATCH_SIZE} \\\n",
    "    --save_dir /content/logs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
